import os
import time
import requests
import hashlib
import hmac
import base64
import re
from typing import List, Optional, Dict, Tuple
from curl_cffi import requests as cffi_requests
from dotenv import load_dotenv
from src.llm_provider import BaseLLMProvider, get_llm_provider
from src.trademark_blacklist import contains_trademark, filter_trademarked_keywords

from src.keyword_stop_words import KEYWORD_STOP_WORDS

load_dotenv()

class KeywordProcessor:
    """
    ê°•í™”ëœ í‚¤ì›Œë“œ í”„ë¡œì„¸ì„œ.
    
    3-Phase ì›Œí¬í”Œë¡œìš°:
        Phase 1: ë‹¤ê°ë„ ì‹œë“œ(Seed) ìˆ˜ì§‘ - ìƒí’ˆëª… ë³€í˜• + ë‹¤íšŒ ê²€ìƒ‰
        Phase 2: ê²½ìŸë„ ê¸°ë°˜ í•„í„°ë§ - ë„¤ì´ë²„ API ë°ì´í„° í™œìš© + ë¶ˆìš©ì–´(Stop Words) ì œê±°
        Phase 3: ìƒí‘œê¶Œ ì´ì¤‘ ê²€ì¦ + LLM ìµœì¢… íë ˆì´ì…˜
    """
    
    def __init__(self, llm_provider: Optional[BaseLLMProvider] = None):
        # Naver Ad API Config (ê²€ìƒ‰ê´‘ê³  API)
        self.naver_base_url = os.getenv("NAVER_API_BASE_URL", "https://api.naver.com")
        self.naver_api_key = os.getenv("NAVER_API_KEY")
        self.naver_secret_key = os.getenv("NAVER_SECRET_KEY")
        self.naver_customer_id = os.getenv("NAVER_CUSTOMER_ID")
        
        # LLM Provider
        if llm_provider is None:
            self.llm_provider = get_llm_provider("gemini")
        else:
            self.llm_provider = llm_provider

    # ============================================================
    # Public API (ê¸°ì¡´ ì‹œê·¸ë‹ˆì²˜ ìœ ì§€)
    # ============================================================

    def process_keywords(self, product_name: str, prompt_template: str = None) -> str:
        """
        ê°•í™”ëœ í‚¤ì›Œë“œ ìƒì„± ì›Œí¬í”Œë¡œìš°.
        
        Args:
            product_name: ê°€ê³µëœ ìƒí’ˆëª…
            prompt_template: (ì˜µì…˜) ì‚¬ìš©ì ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ (ìµœì¢… íë ˆì´ì…˜ìš©)
            
        Returns:
            ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ í‚¤ì›Œë“œ ë¬¸ìì—´
        """
        print(f"\n{'='*60}")
        print(f"[í‚¤ì›Œë“œ ìƒì„± ì‹œì‘] ìƒí’ˆëª…: {product_name}")
        print(f"{'='*60}")
        
        # â”€â”€ Phase 1: ë‹¤ê°ë„ ì‹œë“œ ìˆ˜ì§‘ â”€â”€
        print("\nğŸ“Œ Phase 1: ë‹¤ê°ë„ ì‹œë“œ ìˆ˜ì§‘")
        seed_keywords_with_data = self._collect_seeds_multi_round(product_name)
        
        if not seed_keywords_with_data:
            print("âš ï¸ ì‹œë“œ í‚¤ì›Œë“œë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return ""
        
        print(f"   â†’ ì´ {len(seed_keywords_with_data)}ê°œ í›„ë³´ í‚¤ì›Œë“œ ìˆ˜ì§‘ ì™„ë£Œ")
        
        # â”€â”€ Phase 2: ê²½ìŸë„ ê¸°ë°˜ í•„í„°ë§ â”€â”€
        print("\nğŸ“Œ Phase 2: ê²½ìŸë„ ê¸°ë°˜ í•„í„°ë§")
        filtered_keywords = self._filter_by_competition(seed_keywords_with_data)
        print(f"   â†’ í•„í„°ë§ í›„ {len(filtered_keywords)}ê°œ í‚¤ì›Œë“œ ìƒì¡´")
        
        if not filtered_keywords:
            # í•„í„°ë§ í›„ ë„ˆë¬´ ì ìœ¼ë©´ ê²½ìŸë„ í•„í„° ì™„í™” (í‚¤ì›Œë“œëª…ë§Œì´ë¼ë„ ì‚¬ìš©)
            print("   âš ï¸ ê²½ìŸë„ í•„í„° ê²°ê³¼ê°€ ë„ˆë¬´ ì ì–´ ì›ë³¸ í‚¤ì›Œë“œëª…ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            filtered_keywords = [
                {"keyword": item["keyword"], "compIdx": "ë¶ˆëª…", "totalQcCnt": 0}
                for item in seed_keywords_with_data
            ]
        
        # â”€â”€ Phase 3: ìƒí‘œê¶Œ ê²€ì¦ + LLM íë ˆì´ì…˜ â”€â”€
        print("\nğŸ“Œ Phase 3: ìƒí‘œê¶Œ ê²€ì¦ + LLM íë ˆì´ì…˜")
        final_keywords = self._finalize_keywords(product_name, filtered_keywords, prompt_template)
        
        # ìµœëŒ€ 10ê°œë¡œ ì œí•œ
        final_keywords = final_keywords[:10]
        
        print(f"\n{'='*60}")
        print(f"[ê²°ê³¼] ìµœì¢… í‚¤ì›Œë“œ ({len(final_keywords)}ê°œ): {final_keywords}")
        print(f"{'='*60}\n")
        
        return ", ".join(final_keywords)

    # ============================================================
    # Phase 1: ë‹¤ê°ë„ ì‹œë“œ ìˆ˜ì§‘
    # ============================================================

    def _collect_seeds_multi_round(self, product_name: str) -> List[Dict]:
        """
        ì›ë³¸ ìƒí’ˆëª… + LLM ë³€í˜• ìƒí’ˆëª…ìœ¼ë¡œ ë‹¤íšŒ ê²€ìƒ‰í•˜ì—¬ ì‹œë“œ í‚¤ì›Œë“œë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        
        Returns:
            List[Dict]: [{"keyword": "...", "monthlyPcQcCnt": N, "monthlyMobileQcCnt": N, "compIdx": "ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ"}, ...]
        """
        all_keywords = {}  # keyword -> data dict (ì¤‘ë³µ ì œê±°ìš©)
        
        # Round 1: ì›ë³¸ ìƒí’ˆëª…ìœ¼ë¡œ ê²€ìƒ‰
        print(f"   [Round 1] ì›ë³¸ ìƒí’ˆëª…: '{product_name}'")
        round1_results = self._search_naver_keywords_with_data(product_name)
        round1_coupang = self._get_coupang_related_keywords(product_name)
        
        for item in round1_results:
            all_keywords[item["keyword"]] = item
        
        # ì¿ íŒ¡ í‚¤ì›Œë“œëŠ” ê²€ìƒ‰ëŸ‰ ë°ì´í„° ì—†ì´ í‚¤ì›Œë“œëª…ë§Œ ì¶”ê°€
        for kw in round1_coupang:
            if kw not in all_keywords:
                all_keywords[kw] = {"keyword": kw, "monthlyPcQcCnt": 0, "monthlyMobileQcCnt": 0, "compIdx": "ë¶ˆëª…"}
        
        print(f"      â†’ {len(round1_results)}ê°œ (ë„¤ì´ë²„) + {len(round1_coupang)}ê°œ (ì¿ íŒ¡)")
        
        # Round 2~3: LLMìœ¼ë¡œ ìƒí’ˆëª… ë³€í˜• í›„ ì¬ê²€ìƒ‰
        variations = self._generate_product_name_variations(product_name)
        
        for i, variation in enumerate(variations, start=2):
            print(f"   [Round {i}] ë³€í˜• ìƒí’ˆëª…: '{variation}'")
            round_results = self._search_naver_keywords_with_data(variation)
            round_coupang = self._get_coupang_related_keywords(variation)
            
            for item in round_results:
                if item["keyword"] not in all_keywords:
                    all_keywords[item["keyword"]] = item
            
            for kw in round_coupang:
                if kw not in all_keywords:
                    all_keywords[kw] = {"keyword": kw, "monthlyPcQcCnt": 0, "monthlyMobileQcCnt": 0, "compIdx": "ë¶ˆëª…"}
            
            print(f"      â†’ {len(round_results)}ê°œ (ë„¤ì´ë²„) + {len(round_coupang)}ê°œ (ì¿ íŒ¡)")
        
        return list(all_keywords.values())

    def _generate_product_name_variations(self, product_name: str) -> List[str]:
        """
        LLMì„ ì‚¬ìš©í•˜ì—¬ ìƒí’ˆëª…ì˜ ë™ì˜ì–´/ì•½ì¹­/ë‹¤ë¥¸ ê´€ì  ë³€í˜•ì„ 2~3ê°œ ìƒì„±í•©ë‹ˆë‹¤.
        """
        if not self.llm_provider.is_configured():
            return []
        
        try:
            prompt = f"""ì—­í• : ì˜¨ë¼ì¸ ì‡¼í•‘ í‚¤ì›Œë“œ ì „ë¬¸ê°€
ì‘ì—…: ë‹¤ìŒ ìƒí’ˆëª…ì„ ì†Œë¹„ìê°€ ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” ë‹¤ë¥¸ í‘œí˜„ìœ¼ë¡œ 2~3ê°œ ë³€í˜•í•´ì£¼ì„¸ìš”.

ê·œì¹™:
1. ë™ì˜ì–´, ì•½ì¹­, ë‹¤ë¥¸ ê´€ì ì˜ í‘œí˜„ì„ ì‚¬ìš©
2. ë¸Œëœë“œëª…ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
3. ê° ë³€í˜•ì€ ìì—°ìŠ¤ëŸ¬ìš´ ê²€ìƒ‰ì–´ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤
4. ê²°ê³¼ë§Œ ì¶œë ¥ (í•œ ì¤„ì— í•˜ë‚˜ì”©, ë²ˆí˜¸ ì—†ì´)

ìƒí’ˆëª…: "{product_name}"
ë³€í˜•:"""
            
            result = self.llm_provider.generate_content(prompt)
            variations = [v.strip().strip('-').strip('â€¢').strip() for v in result.strip().split('\n') if v.strip()]
            # ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ
            variations = variations[:3]
            print(f"   [LLM] ìƒí’ˆëª… ë³€í˜• ìƒì„±: {variations}")
            return variations
            
        except Exception as e:
            print(f"   âš ï¸ ìƒí’ˆëª… ë³€í˜• ìƒì„± ì‹¤íŒ¨: {e}")
            return []

    def _search_naver_keywords_with_data(self, keyword: str) -> List[Dict]:
        """
        ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  APIë¡œ ì—°ê´€ í‚¤ì›Œë“œ + ê²€ìƒ‰ëŸ‰/ê²½ìŸë„ ë°ì´í„°ë¥¼ í•¨ê»˜ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        
        Returns:
            List[Dict]: [{"keyword": "...", "monthlyPcQcCnt": N, "monthlyMobileQcCnt": N, "compIdx": "ë†’ìŒ"}, ...]
        """
        if not (self.naver_api_key and self.naver_secret_key):
            return []
        
        try:
            uri = '/keywordstool'
            method = 'GET'
            # Naver API may reject keywords with spaces in some contexts or treat them as invalid.
            # Removing spaces for the search query often helps for compound words in Korean.
            clean_keyword = keyword.replace(" ", "")
            params = {'hintKeywords': clean_keyword, 'showDetail': '1'}
            headers = self._get_naver_header(method, uri)
            resp = requests.get(self.naver_base_url + uri, params=params, headers=headers, timeout=10)
            
            if resp.status_code == 200:
                data = resp.json()
                results = []
                for item in data.get('keywordList', []):
                    kw = item.get('relKeyword', '')
                    if not kw:
                        continue
                    
                    # ê²€ìƒ‰ëŸ‰ ë°ì´í„° ì¶”ì¶œ (< 10 ë“± ë¬¸ìì—´ì¼ ìˆ˜ ìˆìŒ)
                    pc_qc = item.get('monthlyPcQcCnt', 0)
                    mobile_qc = item.get('monthlyMobileQcCnt', 0)
                    
                    # "< 10" ê°™ì€ ë¬¸ìì—´ ì²˜ë¦¬
                    if isinstance(pc_qc, str):
                        pc_qc = 5  # "< 10"ì˜ ê²½ìš° ë³´ìˆ˜ì ìœ¼ë¡œ 5ë¡œ ì²˜ë¦¬
                    if isinstance(mobile_qc, str):
                        mobile_qc = 5
                    
                    results.append({
                        "keyword": kw,
                        "monthlyPcQcCnt": pc_qc,
                        "monthlyMobileQcCnt": mobile_qc,
                        "totalQcCnt": pc_qc + mobile_qc,
                        "compIdx": item.get('compIdx', 'ë¶ˆëª…'),  # ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ
                    })
                return results
            else:
                try:
                    error_msg = resp.json().get('message', 'Unknown Error')
                    print(f"      âš ï¸ ë„¤ì´ë²„ API ì‘ë‹µ ì˜¤ë¥˜ ({resp.status_code}): {error_msg}")
                except:
                    print(f"      âš ï¸ ë„¤ì´ë²„ API ì‘ë‹µ ì˜¤ë¥˜ ({resp.status_code})")
                return []
        except Exception as e:
            print(f"      âš ï¸ ë„¤ì´ë²„ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return []

    def _get_coupang_related_keywords(self, keyword: str) -> List[str]:
        """ì¿ íŒ¡ ì—°ê´€ ê²€ìƒ‰ì–´ ìˆ˜ì§‘"""
        try:
            base_url = "https://www.coupang.com/n-api/web-adapter/search"
            params = {"keyword": keyword}
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
            }
            res = cffi_requests.get(base_url, params=params, headers=headers, impersonate="chrome124", timeout=10)
            if res.status_code != 200:
                return []
            data = res.json()
            return [item.get("keyword") for item in data if item.get("keyword")]
        except Exception:
            return []

    # ============================================================
    # Phase 2: ê²½ìŸë„ ê¸°ë°˜ í•„í„°ë§
    # ============================================================

    def _filter_by_competition(self, keywords_data: List[Dict]) -> List[Dict]:
        """
        ê²½ìŸë„ì™€ ê²€ìƒ‰ëŸ‰ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì†Œìƒê³µì¸ì— ì í•©í•œ í‚¤ì›Œë“œë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤.
        
        í•„í„°ë§ ê¸°ì¤€:
        - ë¶ˆìš©ì–´(Stop Words) í¬í•¨ í‚¤ì›Œë“œ ì œê±°
        - ê²½ìŸë„ "ë†’ìŒ" í‚¤ì›Œë“œ ì œê±° (ëŒ€ê¸°ì—… ë…ì  ì˜ì—­)
        - ë‹¨ì¼ ë‹¨ì–´ í‚¤ì›Œë“œ ì œê±° (ë„ˆë¬´ ê´‘ë²”ìœ„)
        - ë¡±í…Œì¼ í‚¤ì›Œë“œ(2ë‹¨ì–´ ì´ìƒ) ìš°ì„ 
        """
        filtered = []
        removed_reasons = []
        
        for item in keywords_data:
            kw = item["keyword"]
            comp_idx = item.get("compIdx", "ë¶ˆëª…")
            total_qc = item.get("totalQcCnt", 0)
            
            # 0. ë¶ˆìš©ì–´(Stop Words) í•„í„°ë§
            if self._is_stop_word(kw):
                 removed_reasons.append(f"   ğŸš« '{kw}' â†’ ë¶ˆìš©ì–´ í¬í•¨")
                 continue

            # 1. ê²½ìŸë„ "ë†’ìŒ" ì œê±°
            if comp_idx == "ë†’ìŒ":
                removed_reasons.append(f"   ğŸš« '{kw}' â†’ ê²½ìŸë„ ë†’ìŒ")
                continue
            
            # 2. ë‹¨ì¼ ê¸€ì í‚¤ì›Œë“œ ì œê±° (ë„ˆë¬´ ê´‘ë²”ìœ„)
            if len(kw.replace(" ", "")) <= 1:
                removed_reasons.append(f"   ğŸš« '{kw}' â†’ ë„ˆë¬´ ì§§ìŒ")
                continue
            
            # 3. ë‹¨ì¼ ë‹¨ì–´ì´ë©´ì„œ 2ê¸€ì ì´í•˜ì¸ ê²½ìš° ì œê±°
            words = kw.split()
            if len(words) == 1 and len(kw) <= 2:
                removed_reasons.append(f"   ğŸš« '{kw}' â†’ ë‹¨ì¼ ì§§ì€ ë‹¨ì–´")
                continue
            
            # ë¡±í…Œì¼ ë³´ë„ˆìŠ¤ ì ìˆ˜ ê³„ì‚°
            longtail_score = 0
            if len(words) >= 3:
                longtail_score = 2  # 3ë‹¨ì–´ ì´ìƒ
            elif len(words) >= 2:
                longtail_score = 1  # 2ë‹¨ì–´
            
            item["longtail_score"] = longtail_score
            item["quality_score"] = longtail_score + (1 if comp_idx == "ë‚®ìŒ" else 0)
            
            filtered.append(item)
        
        # ë””ë²„ê·¸: ì œê±°ëœ í‚¤ì›Œë“œ ì¼ë¶€ ì¶œë ¥ (ìµœëŒ€ 10ê°œ)
        if removed_reasons:
            for reason in removed_reasons[:10]:
                print(reason)
            if len(removed_reasons) > 10:
                print(f"   ... ì™¸ {len(removed_reasons) - 10}ê°œ ì¶”ê°€ ì œê±°")
        
        # í’ˆì§ˆ ì ìˆ˜ ê¸°ì¤€ ì •ë ¬ (ë†’ì€ ì ìˆ˜ ìš°ì„ )
        filtered.sort(key=lambda x: x.get("quality_score", 0), reverse=True)
        
        return filtered

    # ============================================================
    # Phase 3: ìƒí‘œê¶Œ ê²€ì¦ + LLM ìµœì¢… íë ˆì´ì…˜
    # ============================================================

    def _finalize_keywords(self, product_name: str, keywords_data: List[Dict], prompt_template: str = None) -> List[str]:
        """
        ìƒí‘œê¶Œ ì´ì¤‘ ê²€ì¦ + LLM ìµœì¢… íë ˆì´ì…˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        """
        keyword_names = [item["keyword"] for item in keywords_data]
        
        # â”€â”€ Step 1: ìƒí‘œê¶Œ ë¸”ë™ë¦¬ìŠ¤íŠ¸ 1ì°¨ í•„í„° â”€â”€
        safe_keywords, removed_keywords = filter_trademarked_keywords(keyword_names)
        
        if removed_keywords:
            print(f"   [ë¸”ë™ë¦¬ìŠ¤íŠ¸] {len(removed_keywords)}ê°œ ìƒí‘œ í‚¤ì›Œë“œ ì œê±°: {removed_keywords[:5]}{'...' if len(removed_keywords) > 5 else ''}")
        
        print(f"   [ë¸”ë™ë¦¬ìŠ¤íŠ¸] {len(safe_keywords)}ê°œ í‚¤ì›Œë“œ í†µê³¼")
        
        if not safe_keywords:
            return []
        
        # ì•ˆì „í•œ í‚¤ì›Œë“œì— ëŒ€í•œ ë°ì´í„° ì¬ë§¤í•‘
        safe_data = [item for item in keywords_data if item["keyword"] in safe_keywords]
        
        # â”€â”€ Step 2: LLM ìƒí‘œê¶Œ 2ì°¨ ê²€ì¦ + ìµœì¢… íë ˆì´ì…˜ â”€â”€
        if not self.llm_provider.is_configured():
            return safe_keywords[:10]
        
        final_keywords = self._curate_with_llm(product_name, safe_data, prompt_template)
        
        return final_keywords

    def _curate_with_llm(self, product_name: str, keywords_data: List[Dict], prompt_template: str = None) -> List[str]:
        """
        LLMìœ¼ë¡œ ìƒí‘œê¶Œ 2ì°¨ ê²€ì¦ + ìµœì¢… í‚¤ì›Œë“œ íë ˆì´ì…˜ì„ ë™ì‹œì— ìˆ˜í–‰í•©ë‹ˆë‹¤.
        """
        try:
            # í‚¤ì›Œë“œ + ê²½ìŸë„ ë°ì´í„°ë¥¼ í•¨ê»˜ í¬ë§·
            keyword_info_lines = []
            for item in keywords_data:
                kw = item["keyword"]
                comp = item.get("compIdx", "ë¶ˆëª…")
                total = item.get("totalQcCnt", 0)
                keyword_info_lines.append(f"- {kw} (ê²½ìŸë„: {comp}, ì›” ê²€ìƒ‰ìˆ˜: {total})")
            
            keywords_info = "\n".join(keyword_info_lines)
            # gpt-5-nano is unstable. Use Simple Prompt + Retry Logic.
            all_keyword_names = ", ".join([item["keyword"] for item in keywords_data])
            
            prompt_v1 = f"""Select 10 safe keywords from this list for '{product_name}'.
List: {all_keyword_names}
Constraint:
- No generic terms like 'Option', 'Random', 'Unit' (e.g. 1ê°œ, 1Set), 'Shipping' terms.
- No trademarks/brands.
Return comma-separated string."""

            prompt_v2 = f"""Extract 10 keywords for '{product_name}' from: {all_keyword_names}.
Safety: No brands. No generic options (color/size/unit).
Format: Comma separated."""

            prompts = [prompt_v1, prompt_v2, prompt_v1] # Retry sequence
            
            final = []
            
            for attempt, attempt_prompt in enumerate(prompts):
                if attempt > 0:
                    print(f"   âš ï¸ LLM Attempt {attempt+1} (Retrying)...")
                
                try:
                    result = self.llm_provider.generate_content(attempt_prompt)
                    # print(f"   [DEBUG] LLM Result: {result}") # Verbose debug
                    
                    if not result:
                        continue
                        
                    # Normalize and split
                    normalized = result.replace('\n', ',')
                    candidates = [k.strip() for k in normalized.split(',') if k.strip()]
                    
                    # Filter trademarks and stop words
                    temp_final = []
                    for kw in candidates:
                        # Basic cleanup
                        kw = re.sub(r'^[\d+\.\-\*\â€¢\s]+', '', kw).strip()
                        if not kw: continue
                        
                        if contains_trademark(kw):
                            # print(f"   âš ï¸ Removed Brand: {kw}")
                            pass
                        elif self._is_stop_word(kw):
                             # print(f"   âš ï¸ Removed Stop Word: {kw}")
                             pass
                        else:
                            temp_final.append(kw)
                    
                    if temp_final:
                        final = temp_final
                        break # Success
                        
                except Exception as e:
                    print(f"   âš ï¸ LLM Error: {e}")
                    continue

            # Fallback if all LLM attempts fail
            if not final:
                print("   âš ï¸ LLM Failed all attempts. Using Top 10 by logic.")
                # Simple logic fallback
                final = [item["keyword"] for item in keywords_data[:10] if not contains_trademark(item["keyword"]) and not self._is_stop_word(item["keyword"])]
            
            print(f"   [LLM] ìµœì¢… ì„ ë³„ ({len(final)}ê°œ): {final}")
            return final
            
        except Exception as e:
            print(f"   âš ï¸ LLM íë ˆì´ì…˜ ì¤‘ ì˜¤ë¥˜: {e}")
            # Fallback: ìƒí‘œ ì•ˆì „ í‚¤ì›Œë“œì—ì„œ ìƒìœ„ 10ê°œ ë°˜í™˜
            return [item["keyword"] for item in keywords_data[:10]]

    def _is_stop_word(self, keyword: str) -> bool:
        """
        í‚¤ì›Œë“œê°€ ë¶ˆìš©ì–´(Stop Words)ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        
        Args:
            keyword: ê²€ì‚¬í•  í‚¤ì›Œë“œ
            
        Returns:
            True if stop word, False otherwise
        """
        kw = keyword.strip()
        kw_nospace = kw.replace(" ", "")
        
        # 1. Check exact match
        if kw in KEYWORD_STOP_WORDS:
            return True
        if kw_nospace in KEYWORD_STOP_WORDS:
            return True
            
        # 2. Check suffix match for specific categories (e.g., ends with "ë°°ì†¡")
        #  (ë‹¨, "ë¡œì¼“ë°°ì†¡" ê°™ì€ê±´ ë¦¬ìŠ¤íŠ¸ì— ìˆì§€ë§Œ, "ë¹ ë¥¸ë°°ì†¡" ê°™ì€ ë³€ì¢… ì²˜ë¦¬ë¥¼ ìœ„í•¨)
        if kw.endswith("ë°°ì†¡") or kw.endswith("ë°œì†¡"):
            return True
            
        # 3. Check for specific substring patterns (careful not to over-filter)
        # "1ê°œ", "2ì„¸íŠ¸" ë“± ìˆ˜ëŸ‰/ë‹¨ìœ„ íŒ¨í„´ ì²´í¬
        # 'ê°œ' 'ì„¸íŠ¸' ë“±ìœ¼ë¡œ ëë‚˜ëŠ” ì§§ì€ ë‹¨ì–´ (ìˆ«ì+ë‹¨ìœ„ ì¡°í•©)
        if re.match(r'^\d+(ê°œ|ì„¸íŠ¸|ë¬¶ìŒ|ë°•ìŠ¤|íŒ©|í†µ|ë³‘|ë§¤|ì¥|ë¡¤|ì¼¤ë ˆ|ì¡±|pcs|ea|set)$', kw_nospace, re.IGNORECASE):
            return True
            
        # 4. Check if keyword *contains* stop words that should never appear (Specific Garbage)
        # e.g., "í•˜íŠ¸", "ëœë¤"
        for stop in KEYWORD_STOP_WORDS:
            # "ë°°ì†¡" ê°™ì€ê±´ í¬í•¨ë˜ì–´ë„ "ë°°ì†¡ë¹„" ì²˜ëŸ¼ ëœ ìœ„í—˜í•  ìˆ˜ ìˆì§€ë§Œ, 
            # "ëœë¤", "ì˜µì…˜" ë“±ì€ í¬í•¨ë˜ë©´ ê±°ì˜ 100% ì“°ë ˆê¸°
            if stop in ["ëœë¤", "ëœë¤ë°œì†¡", "ì˜µì…˜", "ì„ íƒ", "í•˜íŠ¸", "ë³„", "ìª½", "ê¸°ë³¸"]:
                 if stop in kw:
                     return True
                     
        return False

    # ============================================================
    # ìœ í‹¸ë¦¬í‹°
    # ============================================================

    def _get_naver_header(self, method, uri):
        """ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  API ì¸ì¦ í—¤ë” ìƒì„±"""
        timestamp = str(round(time.time() * 1000))
        message = f"{timestamp}.{method}.{uri}"
        secret_key = self.naver_secret_key
        hash = hmac.new(bytes(secret_key, "utf-8"), bytes(message, "utf-8"), hashlib.sha256)
        signature = base64.b64encode(hash.digest()).decode()
        return {
            "Content-Type": "application/json; charset=UTF-8",
            "X-Timestamp": timestamp,
            "X-API-KEY": self.naver_api_key,
            "X-Customer": self.naver_customer_id,
            "X-Signature": signature
        }


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    kp = KeywordProcessor()
    print(kp.process_keywords("ìŠ¤í… ì›í˜• ë¹¨ë˜ ê±´ì¡°ëŒ€"))
