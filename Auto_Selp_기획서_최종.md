# Auto-Selp 기획서

## 1. 제안 요청

### 1.1 프로젝트 소개
Auto-Selp는 이커머스(네이버 쇼핑, 쿠팡 등) 초보 셀러(대학생, 직장인 등 투잡/부업 목적)를 위한 **완전 자동화 상품 정보 가공 솔루션**입니다. 판매자가 업로드한 원본 엑셀 파일을 바탕으로 LLM(OpenAI, GPT-5-Nano)과 네이버 오픈 API를 활용하여 최적화된 상품명, 경쟁력 있는 롱테일 키워드, 그리고 카테고리 매핑을 완전히 자동으로 수행합니다. 사용자가 가만히 두기만 해도 한 달에 100만 원 이상의 부수익을 창출할 수 있도록 소싱 업무를 완벽히 돕는 것을 핵심 목표로 합니다.

### 1.2 시장 조사
- **투잡/N잡 열풍과 초보 셀러의 증가**: 대학생, 직장인들의 추가 수입 파이프라인 확보 목적으로 이커머스 시장 진입이 계속해서 급증하고 있습니다.
- **기존 소싱 업무의 한계**: 기존에는 경쟁력 있는 상품명 작성, 키워드 발굴, 카테고리 매칭 등 데이터를 가공하는 데에 셀러가 직접 하루 10시간 이상의 고된 수작업(노가다)을 수반해야 했고, 이는 초보자들이 쉽게 지치고 포기하는 가장 큰 원인이 되었습니다.
- **자동화 솔루션의 폭발적 수요**: 전문적인 지식이나 많은 시간 투자 없이도 시스템이 알아서 상품 데이터를 최적화해주는 '완벽 자동화' 서비스에 대한 수요가 매우 큽니다.

### 1.3 유사 프로그램 분석
- **기존 서비스(아이템스카우트, 판다랭크 등)와의 극명한 차이점**:
  - 기존 서비스들은 방대한 키워드 데이터를 그저 사용자에게 '보여주는' 데에 그쳤습니다. 따라서, 사용자가 그 데이터를 분석하고 판단하여 재가공하는 데 수많은 시간을 써야만 했습니다.
  - **Auto-Selp 핵심 차이점**: Auto-Selp는 단순 통계 제시에 머무르지 않고, 엑셀 대량 업로드 한 번이면 즉시 쇼핑몰 단에 업로드할 수 있는 **'완성된 데이터'를 자동으로 산출**합니다. 즉, 인간의 지루한 개입을 최소화한 '완벽 자동화'를 가장 큰 차별점으로 내세웁니다.

### 1.4 주요 기능
1. **엑셀 대량 완벽 처리 및 병렬 작업 (Parallel Processing)**:
   - 엑셀 업로드 시 컬럼 자동 매핑 및 설정 저장 기능(초보자를 위한 간편성 보장).
   - 멀티 스레딩(1~10개)을 통한 대용량 엑셀 데이터의 압도적으로 빠른 병렬 처리.
2. **지능형 키워드 생성 및 필터링**:
   - 다단계 파이프라인: 시드 수집 -> 네이버 API 기반 데이터 필터링(경쟁률, 검색량) -> 상표권 검증 -> LLM 최종 큐레이션(최대 10개)으로 즉시 쓸 수 있는 키워드 도출.
3. **상품명 가공 및 카테고리 자동 매핑**:
   - LLM을 활용한 SEO 최적화 상품명 자동 생성.
   - 엑셀 로컬 캐싱 및 네이버 API 풀백을 통해 높은 정확도로 빠르고 완벽한 카테고리 자동 매칭 구현.
4. **실시간 프리미엄 작업 트래킹**:
   - 최근 활동 로그 화면 제공, 각 단계별(상품명, 키워드, 카테고리) 및 행별 실시간 프로세스 진행률(%) 확인 지원.

### 1.5 기대 효과
- **획기적인 시간 단축**: 하루 10시간씩 걸리던 수작업 데이터 가공 업무를 시스템이 순식간에 대신 처리하여, 사용자는 본업에 집중하면서도 쇼핑몰 운영이 가능합니다.
- **안정적인 부수익 창출**: 초보자도 고도의 SEO 훈련을 받은 전문가 수준의 퀄리티를 얻게 되어, '가만히 둬도 월 100만 원' 수준의 안정적 수익을 내게 됩니다.
- **진입 장벽 완화**: 복잡한 키워드 분석이나 상표권 지식 없이도 쉽고 안전하게 대량의 상품 가공/등록이 가능해집니다.

### 1.6 개발 환경
- **Frontend**: React (Vite 기반), 다크/화이트 모드 지원 및 초보자 층에게 친화적이고 직관적인 UX를 갖춘 UI 구조.
- **Backend**: Python (멀티스레딩/워커 기반의 병렬 처리 시스템 최적화 구현).
- **Database**: PostgreSQL (작업 진행도 저장, 히스토리 조회 등 안정적 RDBMS).
- **AI/API**: OpenAI, 자체/외부 LLM(GPT-5-Nano), 네이버 쇼핑 오픈 API.
- **인프라/DevOps**: Oracle Cloud(Oracle Linux 9), Docker & Docker Compose 컨테이너화 활용, GitHub Actions 기반 자동화 CI/CD.

---

## 2. 업무 분석 및 요건 정의

### 2.1 업무 분석 (프리미엄 자동화 파이프라인)

Auto-Selp의 업무 프로세스는 크게 **[데이터 준비] → [시스템 가공 (AI/API)] → [결과 도출]**의 3단계로 이루어집니다. 초보 셀러의 개입을 최소화하는 완전 자동화 파이프라인으로 설계되었습니다.

#### 🎯 Auto-Selp 핵심 업무 Flow

| 단계 | 프로세스명 | 사용자 동작 (Seller) | 시스템 자동화 동작 (Auto-Selp) | 비고 |
| :---: | :--- | :--- | :--- | :--- |
| **1** | 엑셀 데이터 업로드 | 도매처 원본 엑셀 리스트 드래그 앤 드롭 | - 엑셀 컬럼 파싱 및 과거 사용 이력 기반 헤더 자동 매핑<br>- 병렬 처리 스레드 풀 생성 (1~10개) | 초보자도 설정 없이 원클릭 가능 |
| **2** | 지능형 상품명 가공 | *(대기 또는 다른 업무 수행)* | - **LLM (GPT-5-Nano 등)** 호출<br>- 핵심 키워드를 조합하여 가독성 높고 SEO에 최적화된 상품명 생성 | 글자수 제한, 금칙어 필터링 적용 |
| **3** | 황금 키워드 추출 | *(대기 또는 다른 업무 수행)* | - 시드 키워드 수집 (LLM/API)<br>- 네이버 데이터랩 API: 검색량/경쟁률 필터링<br>- 특허청 KIPRIS (또는 내부 DB): 상표권 블랙리스트 검열<br>- 최종 10개 핵심 롱테일 키워드 큐레이션 | 리스크 제로 & 상위노출 최적화 |
| **4** | 카테고리 로켓 매칭 | *(대기 또는 다른 업무 수행)* | - 가공된 상품명을 기반으로 네이버 API 카테고리 검색<br>- 내부 DB(PostgreSQL Cache) 확인 후 매칭 속도 극대화 | API 호출 절약 및 매칭 정확도 향상 |
| **5** | 최종 결과 다운로드 | 가공 완료 알림 확인 후 다운로드 | - 2~4단계의 데이터를 하나의 완벽한 엑셀 파일로 병합<br>- 실시간 진행률(Progress Bar) 표시 및 로깅 | 즉시 쇼핑몰(스마트스토어 등) 업로드 가능 포맷 |

#### 💡 기존 대비 업무 효율성 시각화

> **AS-IS (기존 프로세스)** : `소싱(1h)` ➔ `아이템스카우트 검색(3h)` ➔ `상표권 확인(2h)` ➔ `상품명/카테고리 수동 엑셀 기입(4h)` = **총 10시간 (수작업)**
> 
> **TO-BE (Auto-Selp)** : `소싱(1h)` ➔ `엑셀 파일 업로드(1 min)` ➔ ☕ 커피 타임 (시스템 완전 자동 처리) = **총 1시간 1분 (사용자 개입 1분)**

### 2.2 요구 사항 명세
1. 화면 해상도 및 테마(모드)에 따라 UI 텍스트와 레이아웃이 가시적, 미적으로 완벽하게 표현되어야 함 (초보자들도 쓰기 쉽게 화이트/다크 모드 가독성에 심혈).
2. LLM 호출 시 한글 인코딩 문제 없이 단 1건의 누락도 발생하지 않도록 안정적인 Request 로직이 필요.
3. 실패 시 자동 재요청(Retry) 메커니즘이 강제되어, 사용자가 재작업을 할 일을 일절 만들지 않아야 함 ("가만히 둬도 구동되게끔 구축").

*(유스케이스 다이어그램, 프로토타이핑, 전체/단위 업무 흐름도, 단위 업무 정의서는 Notion 등에 추가적으로 디자인 툴을 통해 구성)*

---

## 3. 기획 & 설계

### 3-1. 데이터베이스 설계
- **RDBMS**: 안정적인 관계형 데이터베이스인 PostgreSQL 도입.
- **논리 모델 (예비 ERD)**:
  - `User`: 사용자 정보 (로그인, 토큰 등 기본적인 식별 체계)
  - `Job` / `JobDetails`: 엑셀 단위별 메인 작업 테이블과 엑셀Row별 상태를 관리하는 자식 테이블로 구성 (실시간 퍼센트 트래킹 목적)
  - `Prompt`: 튜닝을 위한 커스텀 프롬프트 저장 테이블
  - `CategoryCache`: 잦은 네이버 카테고리 요청 감소를 위한 로컬 캐싱 역할 테이블

### 3-2. 기획 및 화면 설계
- **정책정의서**: (미정) 향후 동시 접속자 수, 하루 처리 건수, 무료/유료 제한 등 비즈니스 과금 정책 등에 맞게 상세화 예정. 초기 버전은 제한 없는 기능 고도화에 집중.
- **메뉴구조도 (사이트맵)**:
  - 데시보드 홈 (최근 처리된 파일, 요약 상태)
  - 대량 엑셀 원클릭 처리
  - 프롬프트/커스텀 설정
  - 이전 작업 히스토리 목록 다운로드

### 3-3. 프로그램 설계
- **프로그램 목록 및 상세**: 
  - 대량 비동기 엑셀 파서 & 작업 스풀러(`ThreadPoolExecutor`).
  - Open API Wrapper & LLM Prompt Template 생성기.
- **REST API 설계 (주요 스펙)**:
  - `POST /api/upload`: 엑셀 파일 업로드 및 옵션 병합 등 백그라운드 job submit.
  - `GET /api/jobs/{id}/status`: 폴링 기반으로 웹에서 진행률을 그리기 위한 상태 반환 기능.
  - `POST /api/jobs/{id}/cancel`: 유저의 변심 등에 의한 즉각적인 스레드 중단 기능.

### 3-4. 테스트 설계
- 멀티스레드 10개 병렬 처리 시 안정적인 속도 보장 여부 (Throttling 및 메모리 안정성) 단위 테스트.
- 불규칙한 엑셀 파일 업로드 시에 대한 시스템 예외 회피 통합 테스트 시나리오 마련.
